services:
  # Spring Boot Application
  logsentry-api:
    build: .
    container_name: logsentry-api
    ports:
      - "${APP_PORT}:8081"
    env_file:
      - .env
    environment:
      - SPRING_PROFILES_ACTIVE=${SPRING_PROFILES_ACTIVE}
    depends_on:
      - otel-collector
    networks:
      - logsentry
    volumes:
      - ${PWD}/logs:/app/logs
    restart: unless-stopped

  # OpenTelemetry Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: otel-collector
    command: ["--config=/etc/otel-collector-config.yml"]
    volumes:
      - ${PWD}/otel-config.yml:/etc/otel-collector-config.yml:ro
    ports:
      - "${OTEL_GRPC_PORT}:4317"   # OTLP gRPC receiver
      - "${OTEL_HTTP_PORT}:4318"   # OTLP HTTP receiver
      - "8888:8888"   # Prometheus metrics
      - "8889:8889"   # Prometheus exporter metrics
    depends_on:
      tempo:
        condition: service_started
      prometheus:
        condition: service_started
    networks:
      - logsentry
    restart: unless-stopped

  # Grafana Tempo
  tempo:
    image: grafana/tempo:latest
    container_name: tempo
    command: ["-config.file=/etc/tempo.yml"]
    volumes:
      - ${PWD}/tempo.yml:/etc/tempo.yml:ro
      - tempo-data:/var/tempo
    ports:
      - "${TEMPO_PORT}:3200"   # Tempo HTTP
    networks:
      - logsentry
    restart: unless-stopped

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
      - '--web.enable-remote-write-receiver'
      - '--enable-feature=exemplar-storage'
    volumes:
      - ${PWD}/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "${PROMETHEUS_PORT}:9090"
    networks:
      - logsentry
    restart: unless-stopped

  # Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "${GRAFANA_PORT}:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GF_SECURITY_ADMIN_PASSWORD}
    volumes:
      - grafana-data:/var/lib/grafana
    networks:
      - logsentry

  # Kafka
  kafka:
    image: bitnami/kafka:3.7.0
    container_name: kafka
    restart: unless-stopped
    ports:
      - "${KAFKA_PORT}:9092"
      - "9094:9094"
    environment:
      KAFKA_CFG_NODE_ID: 1
      KAFKA_CFG_PROCESS_ROLES: broker,controller
      KAFKA_KRAFT_CLUSTER_ID: kraft-cluster-logsentry
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_CFG_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://0.0.0.0:9094,CONTROLLER://kafka:9093
      KAFKA_CFG_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://${HOST_IP:-localhost}:9094
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: INTERNAL
      ALLOW_PLAINTEXT_LISTENER: "yes"
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_CFG_NUM_PARTITIONS: "3"
      KAFKA_CFG_DEFAULT_REPLICATION_FACTOR: "1"
      KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR: "1"
    volumes:
      - kafka-data:/bitnami/kafka
    networks:
      - logsentry
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--bootstrap-server", "kafka:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Kafka 초기 토픽 생성
  kafka-init:
    image: bitnami/kafka:3.7.0
    container_name: kafka-init
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - logsentry
    command: |
      bash -c "
        kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic app-logs --partitions 3 --replication-factor 1
        kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic metrics --partitions 3 --replication-factor 1
        kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic traces --partitions 3 --replication-factor 1
        sleep 5
      "
    restart: "no"

  # Logstash
  logstash:
    image: docker.elastic.co/logstash/logstash:8.14.3
    container_name: logstash
    networks:
      - logsentry
    depends_on:
      kafka:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
    volumes:
      - ${PWD}/logstash/pipeline:/usr/share/logstash/pipeline:ro
    ports:
      - "5044:5044"
    environment:
      LS_JAVA_OPTS: "-Xms256m -Xmx512m"
    restart: unless-stopped

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.14.3
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.http.ssl.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    networks:
      - logsentry
    volumes:
      - es-data:/usr/share/elasticsearch/data
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:8.14.3
    container_name: kibana
    ports:
      - "5601:5601"
    networks:
      - logsentry
    depends_on:
      elasticsearch:
        condition: service_started
    restart: unless-stopped

volumes:
  tempo-data:
  prometheus-data:
  grafana-data:
  kafka-data:
  es-data:

networks:
  logsentry:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16